---
title: "Week 4 - Homework"
author: "STAT 420, Summer 2020, purohit4@illinois.edu"
date: ''
output:
  html_document: 
    theme: readable
    toc: yes  
  pdf_document: default
urlcolor: cyan
---


***

## Exercise 1 (Using `lm`)

For this exercise we will use the data stored in [`nutrition-2018.csv`](nutrition-2018.csv). It contains the nutritional values per serving size for a large variety of foods as calculated by the USDA in 2018. It is a cleaned version totaling 5956 observations and is current as of April 2018.

The variables in the dataset are:

- `ID` 
- `Desc` - short description of food
- `Water` - in grams
- `Calories` 
- `Protein` - in grams
- `Fat` - in grams
- `Carbs` - carbohydrates, in grams
- `Fiber` - in grams
- `Sugar` - in grams
- `Calcium` - in milligrams
- `Potassium` - in milligrams
- `Sodium` - in milligrams
- `VitaminC` - vitamin C, in milligrams
- `Chol` - cholesterol, in milligrams
- `Portion` - description of standard serving size used in analysis

**(a)** Fit the following multiple linear regression model in `R`. Use `Calories` as the response and `Fat`, `Sugar`, and `Sodium` as predictors.

\[
Y_i = \beta_0 + \beta_1 x_{i1} + \beta_2 x_{i2} + \beta_3 x_{i3} + \epsilon_i.
\]

Here,

- $Y_i$ is `Calories`.
- $x_{i1}$ is `Fat`.
- $x_{i2}$ is `Sugar`.
- $x_{i3}$ is `Sodium`.

Use an $F$-test to test the significance of the regression. 
```{r}
nutrition_df <- read.csv("nutrition-2018.csv")

fit_nutrition_1 <- lm(Calories~Fat+Sugar+Sodium, data = nutrition_df)

```

Report the following:
- The null and alternative hypotheses
$H_0 : \beta_1 = \beta_2 = \beta_3 = 0$ : there is no significant linear relationship between Calories and the Fat, Sugar or Sodium content of food

$H_1$ : Atleast one of $\beta_j \neq 0, j= 1, 2, 3$ : there is a significant linear relationship between Calories and atleast one of Fat, Sugar or Sodium content of food


- The value of the test statistic
```{r}
fstat <- summary(fit_nutrition_1)$fstatistic
fstat[1]
```


- The p-value of the test
```{r}
1-pf(fstat[1], df1 = fstat[2], df2 = fstat[3])
```

- A statistical decision at $\alpha = 0.01$
Since p-value is less than .01 we reject the Null Hypothesis


- A conclusion in the context of the problem
In conclusion we state that atleast one of the parameters: Fat, Sugar or Sodium, has a significant linear relationship with Calories.

<br><br>

**(b)** Output only the estimated regression coefficients. Interpret all $\hat{\beta}_j$ coefficients in the context of the problem.
```{r}
coef(fit_nutrition_1)
```
For $\beta_0$ we see that if Fat, sugar and Sodium are all 0, then the food will have 100 Calories

For $\beta_1$ we see that for the same Sugar and Sodium content, if Fat increases by 1 gram, the calories will increase by 8.48 

For $\beta_2$ we see that for the same Fat and Sodium content, if Sugar increases by 1 gram, the calories will increase by 3.9.

For $\beta_3$ we see that for the same Fat and Sugar content, if Sodium increases by 1 milligram, the calories will increase by .006. 


<br><br>

**(c)** Use your model to predict the number of `Calories` in a Big Mac. According to [McDonald's publicized nutrition facts](https://www.mcdonalds.com/us/en-us/about-our-food/nutrition-calculator.html), the Big Mac contains 30g of fat, 9g of sugar, and 1010mg of sodium.

```{r}
newdata = data.frame(Fat=30, Sugar=9, Sodium=1010)
predict(fit_nutrition_1, newdata = newdata)
```

<br><br>

**(d)** Calculate the standard deviation, $s_y$, for the observed values in the Calories variable. Report the value of $s_e$ from your multiple regression model. Interpret both estimates in the context of this problem.

```{r results='hold'}
y <-  as.matrix(nutrition_df["Calories"])

(Sy <- sd(y))

#Se from multiple regression model
(Se <- summary(fit_nutrition_1)$sigma)
```
Sy is standard deviation of the variable calories. Se is the variability of the residuals of the model

<br><br>

**(e)** Report the value of $R^2$ for the model. Interpret its meaning in the context of the problem.
```{r}
summary(fit_nutrition_1)$r.squared
```
$R^2$ is seen to be .7686 or 76.86%. This implies that 76.86% of the Calories in the data are explained by the model and the remaining are not

<br><br>

**(f)** Calculate a 90% confidence interval for $\beta_2$. Give an interpretation of the interval in the context of the problem.
```{r}
confint(fit_nutrition_1, parm = "Sugar", level = .9)
```

Given the above confidence interval, we are 90% confident that for the same value of Fat and Sodium, when sugar increases by 1, the calories will increase by 3.78 to 4.01

<br><br>

**(g)** Calculate a 95% confidence interval for $\beta_0$. Give an interpretation of the interval in the context of the problem.
```{r}
confint(fit_nutrition_1, parm = "(Intercept)", level = .95)
```

Given the above confidence interval, we are 95% confident that when Fat, Sugar and Sodium are all 0 for a food, then the calories for the food is in between 97.69 and 103.21

<br><br>

**(h)** Use a 99% confidence interval to estimate the mean Calorie content of a food with 23g of fat, 0g of sugar, and 400mg of sodium, which is true of a large order of McDonald's french fries. Interpret the interval in context.
```{r}
predict(fit_nutrition_1, newdata = data.frame("Fat"=23,"Sugar"=0, "Sodium"=400), level = .99)
```
We are 99% confident that if a food has 23gms of fat, 0 gms of sugar and 400mg of sodium then its average calorie count will be 298.04. A large order of McDonals french fries has the said amount of fat, sugar and sodium, hence we can say with 99% confidence that it will have an average of 298 calories.

<br><br>

**(i)** Use a 99% prediction interval to predict the Calorie content of a Crunchwrap Supreme, which has 21g of fat, 6g of sugar, and 1200mg of sodium according to [Taco Bell's publicized nutrition information](https://www.tacobell.com/nutrition/info). Interpret the interval in context.

```{r}
predict(fit_nutrition_1, newdata = data.frame("Fat"=21,"Sugar"=6, "Sodium"=1200), level = .99)
```
We can say with 99% confidence that Crunchwrap supreme has an average calorie count of 309.4 calories. This average calorie count would hold good for any food that has 21 gms of fat, 6gms of sugar and 1200mgs of Sodium and we can say that with 99% confidence


***

## Exercise 2 (More `lm` for Multiple Regression)

For this exercise we will use the data stored in [`goalies.csv`](goalies.csv). It contains career data for 462 players in the National Hockey League who played goaltender at some point up to and including the 2014-2015 season. The variables in the dataset are:
 
- `W` - Wins
- `GA` - Goals Against
- `SA` - Shots Against
- `SV` - Saves
- `SV_PCT` - Save Percentage
- `GAA` - Goals Against Average
- `SO` - Shutouts
- `MIN` - Minutes
- `PIM` - Penalties in Minutes

For this exercise we will consider three models, each with Wins as the response. The predictors for these models are:

- Model 1: Goals Against, Saves
- Model 2: Goals Against, Saves, Shots Against, Minutes, Shutouts
- Model 3: All Available
```{r}
goalies_df <- read.csv("goalies.csv")
fit_model_1 <- lm(W~GA+SV, data = goalies_df)
fit_model_2 <- lm(W~GA+SV+SA+MIN+SO, data = goalies_df)
fit_model_3 <- lm(W~., data = goalies_df)

```

**(a)** Use an $F$-test to compares Models 1 and 2. Report the following:


- The null hypothesis

model 1 is the smaller model. Hence we will use Model 1 as our null model and Model_2 as the full model. We note that the null model is a subset of or is nested in the full model.
$H_0: \beta_3 = \beta_4 = \beta_5 = 0$ : there is no significant linear relationship between Wins vs Shots Against, Minutes and Shutouts OR the beta parameters that are not present in the null model are 0

- The value of the test statistic
```{r}
anova_table_1_2 <- anova(fit_model_1,fit_model_2)
anova_table_1_2$F[2]
```

- The p-value of the test
```{r}
anova_table_1_2$"Pr(>F)"[2]
```

- A statistical decision at $\alpha = 0.05$
Since the p-value is smaller than alpha we reject the null hypothesis 

- The model you prefer
Based on the rejection of the null hypothesis, we say that at least some of the model 2 betas have a significant linear relationship with Wins. Hence we prefer model 2 as a being better at explaining the wins

<br><br>

**(b)** Use an $F$-test to compare Model 3 to your preferred model from part **(a)**. Report the following:
```{r}
anova_table_2_3 <- anova(fit_model_2,fit_model_3)
```

- The null hypothesis
model 2 is the smaller model. Hence we will use Model 2 as our null model and Model 3 as the full model. We note that the null model is a subset of or is nested in the full model.
$H_0: \beta_4 = \beta_5 = \beta_8 = 0$ : the beta parameters that are not present in the null model are 0 OR there is no significant linear relationship between Wins vs Save percentage, Goals against average and penalties in minutes

- The value of the test statistic
```{r}
anova_table_2_3$F[2]
```


- The p-value of the test
```{r}
anova_table_2_3$"Pr(>F)"[2]
```

- A statistical decision at $\alpha = 0.05$

since p-value is less than alpha, we reject the null hypothesis


- The model you prefer
We prefer the 3rd model since based on the hypothesis test, there is a significant relationship between wins and atleast one of the parameters that is extra in the third model

<br><br>

**(c)** Use a $t$-test to test $H_0: \beta_{\texttt{SV}} = 0 \ \text{vs} \ H_1: \beta_{\texttt{SV}} \neq 0$ for the model you preferred in part **(b)**. Report the following:


- The value of the test statistic

```{r}
coef(summary(fit_model_3))["SV", "t value"]

```

- The p-value of the test

```{r}
coef(summary(fit_model_3))["SV", "Pr(>|t|)"]

```
- A statistical decision at $\alpha = 0.05$
Since the p-value is less than alpha, we reject the null hypothesis and accept the alternate hypothesis that there is a significant linear relationship between saves and wins

***

## Exercise 3 (Regression without `lm`)

For this exercise we will once again use the `Ozone` data from the `mlbench` package. The goal of this exercise is to fit a model with `ozone` as the response and the remaining variables as predictors.

```{r}
data(Ozone, package = "mlbench")
Ozone = Ozone[, c(4, 6, 7, 8)]
colnames(Ozone) = c("ozone", "wind", "humidity", "temp")
Ozone = Ozone[complete.cases(Ozone), ]
```

**(a)** Obtain the estimated regression coefficients **without** the use of `lm()` or any other built-in functions for regression. That is, you should use only matrix operations. Store the results in a vector `beta_hat_no_lm`. To ensure this is a vector, you may need to use `as.vector()`. Return this vector as well as the results of `sum(beta_hat_no_lm ^ 2)`.

```{r}
coeffs_no_lm <- function(X, y_data){
  
  beta_hat_no_lm <- solve(t(X) %*% X) %*% t(X) %*% y_data
  return(list(as.vector(beta_hat_no_lm),as.vector(sum(beta_hat_no_lm^2))))
}
```
```{r}
  y_data <-  as.matrix(Ozone["ozone"])
  
  X <- cbind(beta_0=rep(1, nrow(Ozone)), Ozone$wind, Ozone$humidity, Ozone$temp)

  #sum of squares of beta_hat_lm is also returned, but we are not storing it
  beta_hat_no_lm <- coeffs_no_lm(X, y_data)[[1]]
```

<br><br>

**(b)** Obtain the estimated regression coefficients **with** the use of `lm()`. Store the results in a vector `beta_hat_lm`. To ensure this is a vector, you may need to use `as.vector()`. Return this vector as well as the results of `sum(beta_hat_lm ^ 2)`.
```{r}
coeffs_with_lm <- function(fit_model){
  beta_hat_lm <- coef(fit_model)
  return(list(as.vector(beta_hat_lm),as.vector(sum(beta_hat_lm^2))))
}
```

```{r}
fit_ozone <- lm(ozone~.,data = Ozone)
#sum of squares of beta_hat_lm is also returned, but we are not storing it
beta_hat_lm <- (as.matrix(coeffs_with_lm(fit_ozone)[[1]]))

```

<br><br>

**(c)** Use the `all.equal()` function to verify that the results are the same. You may need to remove the names of one of the vectors. The `as.vector()` function will do this as a side effect, or you can directly use `unname()`.
```{r}
all.equal(coeffs_no_lm(X,y_data), coeffs_with_lm(fit_ozone))
```

<br><br>

**(d)** Calculate $s_e$ without the use of `lm()`. That is, continue with your results from **(a)** and perform additional matrix operations to obtain the result. Output this result. Also, verify that this result is the same as the result obtained from `lm()`.
```{r}
# To calculate the predicted results we do X*Beta.
n <- nrow(Ozone)
p <- 3+1

y_pred <- X %*% as.matrix(beta_hat_no_lm)

e = Ozone$ozone - y_pred
Se_nolm <- c(sqrt((t(e) %*% e)/(n-p)))

#Se from multiple regression model
Se <- summary(fit_ozone)$sigma

print(paste("Is the calculated standard error Sy same as the the sigma returned by the fitted model using lm: ", all.equal(Se_nolm, Se)))

```

<br><br>

**(e)** Calculate $R^2$ without the use of `lm()`. That is, continue with your results from **(a)** and **(d)**, and perform additional operations to obtain the result. Output this result. Also, verify that this result is the same as the result obtained from `lm()`.

```{r}
y_bar <- mean(y_data)
R_square_no_lm <- 1 - (sum((y_data-y_pred)^2)/sum((y_data-y_bar)^2))

print(paste("Are the values of R^2 same when calculated without lm and and with lm: ", all.equal(R_square_no_lm, summary(fit_ozone)$r.squared)))
```


***

## Exercise 4 (Regression for Prediction)

For this exercise use the `Auto` dataset from the `ISLR` package. Use `?Auto` to learn about the dataset. The goal of this exercise is to find a model that is useful for **predicting** the response `mpg`. We remove the `name` variable as it is not useful for this analysis. (Also, this is an easier to load version of data from the textbook.)

```{r}
# load required package, remove "name" variable
library(ISLR)
Auto = subset(Auto, select = -c(name))
```

When evaluating a model for prediction, we often look at RMSE. However, if we both fit the model with all the data as well as evaluate RMSE using all the data, we're essentially cheating. We'd like to use RMSE as a measure of how well the model will predict on *unseen* data. If you haven't already noticed, the way we had been using RMSE resulted in RMSE decreasing as models became larger.

To correct for this, we will only use a portion of the data to fit the model, and then we will use leftover data to evaluate the model. We will call these datasets **train** (for fitting) and **test** (for evaluating). The definition of RMSE will stay the same

\[
\text{RMSE}(\text{model, data}) = \sqrt{\frac{1}{n} \sum_{i = 1}^{n}(y_i - \hat{y}_i)^2}
\]

where

- $y_i$ are the actual values of the response for the given data.
- $\hat{y}_i$ are the predicted values using the fitted model and the predictors from the data.

However, we will now evaluate it on both the **train** set and the **test** set separately. So each model you fit will have a **train** RMSE and a **test** RMSE. When calculating **test** RMSE, the predicted values will be found by predicting the response using the **test** data with the model fit using the **train** data. *__Test__ data should never be used to fit a model.*

- Train RMSE: Model fit with *train* data. Evaluate on **train** data.
- Test RMSE: Model fit with *train* data. Evaluate on **test** data.

Set a seed of `11`, and then split the `Auto` data into two datasets, one called `auto_trn` and one called `auto_tst`. The `auto_trn` data frame should contain 292 randomly chosen observations. The `auto_tst` data will contain the remaining observations. Hint: consider the following code:

```{r message=FALSE}
library("dplyr")
set.seed(11)
auto_trn_idx = sample(1:nrow(Auto), 292)
auto_trn <- slice(Auto, auto_trn_idx)
auto_tst <- slice(Auto, -1*auto_trn_idx)
```

Fit a total of five models using the training data.

- One must use all possible predictors.
- One must use only `displacement` as a predictor.
- The remaining three you can pick to be anything you like. One of these should be the *best* of the five for predicting the response.
```{r}
model_1 <- lm(mpg~displacement, data = auto_trn)
model_2 <- lm(mpg~displacement+cylinders+weight, data = auto_trn)
model_3 <- lm(mpg~displacement+cylinders+horsepower+weight, data = auto_trn)
model_4 <- lm(mpg~weight+origin+year, data = auto_trn)
model_5 <- lm(mpg~., data = auto_trn)
```

For each model report the **train** and **test** RMSE. Arrange your results in a well-formatted markdown table. Argue that one of your models is the best for predicting the response.
```{r} 
model_1_train_RMSE <- sqrt(sum((auto_trn["mpg"]-predict(model_1, newdata = auto_trn))^2)/nrow(auto_trn))

model_1_train_RMSE2 <- sqrt(sum((residuals(model_1)^2)/nrow(auto_trn)))

model_2_train_RMSE <- sqrt(sum((auto_trn["mpg"]-predict(model_2))^2)/nrow(auto_trn))
model_3_train_RMSE <- sqrt(sum((auto_trn["mpg"]-predict(model_3))^2)/nrow(auto_trn))
model_4_train_RMSE <- sqrt(sum((auto_trn["mpg"]-predict(model_4))^2)/nrow(auto_trn))
model_5_train_RMSE <- sqrt(sum((auto_trn["mpg"]-predict(model_5))^2)/nrow(auto_trn))

#test the model
model_1_test_RMSE <- sqrt(sum((auto_tst["mpg"]-predict(model_1, newdata=auto_tst))^2)/nrow(auto_tst))

model_2_test_RMSE <- sqrt(sum((auto_tst["mpg"]-predict(model_2, newdata=auto_tst))^2)/nrow(auto_tst))
model_3_test_RMSE <- sqrt(sum((auto_tst["mpg"]-predict(model_3, newdata=auto_tst))^2)/nrow(auto_tst))
model_4_test_RMSE <- sqrt(sum((auto_tst["mpg"]-predict(model_4, newdata=auto_tst))^2)/nrow(auto_tst))
model_5_test_RMSE <- sqrt(sum((auto_tst["mpg"]-predict(model_5, newdata=auto_tst))^2)/nrow(auto_tst))


model_comp_df <- rbind("model 1"=c(model_1_train_RMSE, model_1_test_RMSE), "model 2"=c(model_2_train_RMSE, model_2_test_RMSE),"model 3"=c(model_3_train_RMSE, model_3_test_RMSE),"model 4"=c(model_4_train_RMSE, model_4_test_RMSE),"model 5"=c(model_5_train_RMSE, model_5_test_RMSE))

colnames(model_comp_df) <- c("Train_RMSE", "Test_RMSE")
knitr::kable(model_comp_df, format="markdown")
```
We see that the model using weight, origin and year has the least test RMSE from all 5 models and hence we prefer that model.


***

## Exercise 5 (Simulating Multiple Regression)

For this exercise we will simulate data from the following model:

\[
Y_i = \beta_0 + \beta_1 x_{i1} + \beta_2 x_{i2} + \beta_3 x_{i3} + \beta_4 x_{i4} + \beta_5 x_{i5} + \epsilon_i
\]

Where $\epsilon_i \sim N(0, \sigma^2).$ Also, the parameters are known to be:

- $\beta_0 = 2$
- $\beta_1 = -0.75$
- $\beta_2 = 1.5$ 
- $\beta_3 = 0$
- $\beta_4 = 0$
- $\beta_5 = 2$
- $\sigma^2 = 25$

We will use samples of size `n = 42`.

We will verify the distribution of $\hat{\beta}_2$ as well as investigate some hypothesis tests.

**(a)** We will first generate the $X$ matrix and data frame that will be used throughout the exercise. Create the following nine variables:

- `x0`: a vector of length `n` that contains all `1`
- `x1`: a vector of length `n` that is randomly drawn from a normal distribution with a mean of `0` and a standard deviation of `2`
- `x2`: a vector of length `n` that is randomly drawn from a uniform distribution between `0` and `4`
- `x3`: a vector of length `n` that is randomly drawn from a normal distribution with a mean of `0` and a standard deviation of `1`
- `x4`: a vector of length `n` that is randomly drawn from a uniform distribution between `-2` and `2`
- `x5`: a vector of length `n` that is randomly drawn from a normal distribution with a mean of `0` and a standard deviation of `2`
- `X`: a matrix that contains `x0`, `x1`, `x2`, `x3`, `x4`, and `x5` as its columns
- `C`: the $C$ matrix that is defined as $(X^\top X)^{-1}$
- `y`: a vector of length `n` that contains all `0`
- `sim_data`: a data frame that stores `y` and the **five** *predictor* variables. `y` is currently a placeholder that we will update during the simulation.

Report the sum of the diagonal of `C` as well as the 5th row of `sim_data`. For this exercise we will use the seed `420`. Generate the above variables in the order listed after running the code below to set a seed.

```{r results="hold"}
set.seed(420)
sample_size = 42

x0 <- rep(1, sample_size)
x1 <- rnorm(sample_size, mean=0, sd=2)
x2 <- runif(sample_size, min=0, max=4)
x3 <- rnorm(sample_size, mean=0, sd=1)
x4 <- runif(sample_size, min=-2, max=2)
x5 <- rnorm(sample_size, mean=0, sd=2)
X <- cbind(x0,x1,x2,x3,x4,x5)
C <- solve(t(X) %*% X)
y <- rep(0, sample_size)
sim_data <- data.frame(cbind(y, x1, x2, x3, x4, x5))

c_diag_sum <- 0
for (i in c(1:nrow(C))){
  c_diag_sum <- c_diag_sum + C[i,i]
}

print(paste("sum of diagonal of C = ", c_diag_sum))
print("The 5th row for sim data is : ")
print(sim_data[5,])
```


<br><br>

**(b)** Create three vectors of length `2500` that will store results from the simulation in part **(c)**. Call them `beta_hat_1`, `beta_3_pval`, and `beta_5_pval`.
```{r}
beta_hat_1 <- rep(0, 2500)
beta_3_pval <- rep(0, 2500)
beta_5_pval <- rep(0, 2500)
```

<br><br>

**(c)** Simulate 2500 samples of size `n = 42` from the model above. Each time update the `y` value of `sim_data`. Then use `lm()` to fit a multiple regression model. Each time store:

- The value of $\hat{\beta}_1$ in `beta_hat_1`
- The p-value for the two-sided test of $\beta_3 = 0$ in `beta_3_pval`
- The p-value for the two-sided test of $\beta_5 = 0$ in `beta_5_pval`
```{r}
beta_0 = 2
beta_1 = -0.75
beta_2 = 1.5
beta_3 = 0
beta_4 = 0
beta_5 = 2
sig = 5

for (i in 1:2500){
  epsilon <- rnorm(n=sample_size, mean=0, sd = sig)
  y <- beta_0*x0 + beta_1*x1 + beta_2*x2 + beta_3*x3 + beta_4*x4 + beta_5*x5+ epsilon
  sim_data["y"]=data.frame(y)
  m1 <- lm(y~., data = sim_data)
  beta_hat_1[i] <- coef(m1)[2]
  beta_3_pval[i] <- coef(summary(m1))["x3","Pr(>|t|)"]
  beta_5_pval[i] <- coef(summary(m1))["x5","Pr(>|t|)"]
}

```

<br><br>

**(d)** Based on the known values of $X$, what is the true distribution of $\hat{\beta}_1$?

```{r}
(real_beta_1_var <- sig^2*C[2,2])
```

<br><br>

**(e)** Calculate the mean and variance of `beta_hat_1`. Are they close to what we would expect? Plot a histogram of `beta_hat_1`. Add a curve for the true distribution of $\hat{\beta}_1$. Does the curve seem to match the histogram?


```{r results="hold"}
print(paste("mean of beta_hat_1 = ", mean(beta_hat_1)))
print(paste("The real beta_1 mean = ", beta_1))

print(paste("Variance of beta_hat_1 = ", var(beta_hat_1)))
print(paste("The real variance of beta_1 = ", real_beta_1_var))

```
We see that the mean and variance are very close to each other. This is what we expected.


```{r}
library(ggplot2)

ggplot(data.frame(beta_hat_1), aes(x=beta_hat_1)) + 
    geom_histogram(aes(y=stat(density),color=I("orange")), binwidth = .1) +
    ggtitle("beta_hat_1 distribution based on 2500 simulations") +
    theme_linedraw() +
    stat_function(fun = dnorm, args = list(mean = beta_1, sd = sqrt(real_beta_1_var)), col="red", size=2)

```

We see that the curve matches the histogram and hence we also see that beta_hat_1 is normally distributed.

<br><br>

**(f)** What proportion of the p-values stored in `beta_3_pval` is less than 0.10? Is this what you would expect?
```{r}
mean(beta_3_pval<.1)
```
We already know that beta_3 is 0. Here roughly 10% of the p-values will reject the null hypotheses which is expected with an alpha of .1. Hence this matches our expectation

<br><br>

**(g)** What proportion of the p-values stored in `beta_5_pval` is less than 0.01? Is this what you would expect? 
```{r}
mean(beta_5_pval<.01)
```

We already know that beta_5 is not 0. Hence we see that close to 79% of the observations reject the null hypothesis. Hence this matches our expectations


